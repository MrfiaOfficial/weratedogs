{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n",
    "\n",
    "**This report succinctly describes the wrangling effort carried out for the Wrangle Act Project.**\n",
    "\n",
    "> The Wrangle Act  project objective is to gathered data from three different sources, assessed, cleaned and merged the three cleaned datasets into a master data table. Also, made some analysis to get insights and made some visualizations so as to communicate some of our findings.\n",
    "\n",
    "\n",
    "### Data Gathering: \n",
    "\n",
    "The wrangling process started with the first dataset. The first dataset named “twitter_archive_enhanced.csv” was gathered from importing a csv file which contains the raw data from my local machine. This csv file is provided to us by Udacity. The second dataset “tweet_json.csv” was gathered by querying twitter API using the tweepy library and writing the content into a local csv file which is then imported to our dataframe to be used for this analysis project. The third dataset “image_predictions.tsv” was gathered from Udacity server by using the request library to gathered the data over the internet from Udacity server. This is possible because a third-party has already gatthered the image predictions data through a neural network and provided it to Udacity which was then made available for our use.\n",
    "\n",
    "\n",
    "### Data Assessment:\n",
    "\n",
    "After the three datasets were gathered, they were then imported to three different pandas dataframes for visual assessment after which some quality and tidiness issues were discovered and documented as visual assessment observations. After this, a programmatic assessment was carried out on each dataset which exposed more quality and tidiness issues as well which were all documented as observations.\n",
    "\n",
    "\n",
    "### Data Cleaning:\n",
    "\n",
    "Since the Data assessment efforts have exposed many quality and tidiness issues, I created a list of issues to be addressed which were chosen from the observed issues from the assessment step. I put each of the selected issues to be treated under the name of the Dataset they belong to, so as to prepare a easily readable and understandable workflow. The cleaned dataset were each saved as well as a copy of each of the raw datasets, also the three datasets were all merged into one dataset named “twitter_archive_master.csv”, which is then used for further data exploration and visualizations.\n",
    "\n",
    "\n",
    "### Analysis and Visualizations:\n",
    "\n",
    "In this section, I listed some six questions which are related to what the dataset is all about. These questions guided me to make some exploratory efforts to answer each of the questions. The answers to the stated analysis questions provided needed insights for as required. These insights were also used to generate some visualizations as needed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
